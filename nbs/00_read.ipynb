{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95d05d1",
   "metadata": {},
   "source": [
    "# Read\n",
    "\n",
    "> Read X for llm context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256d9df",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb01b1a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e50fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import httpx \n",
    "import html2text\n",
    "from fastcore.all import delegates, ifnone\n",
    "\n",
    "import re, os, glob, string, warnings, functools\n",
    "import requests\n",
    "import fnmatch, mimetypes\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from toolslm.download import html2md, read_html\n",
    "\n",
    "import tempfile, subprocess, os, re, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Optional, List, Dict, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1428e30",
   "metadata": {},
   "source": [
    "## Defining read_ functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911d6a5",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7593360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_text(url, # URL to read\n",
    "             ): # Text from page\n",
    "    \"Get text from `url`\"\n",
    "    return httpx.get(url, follow_redirects=True).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32541cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta chars'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_text('https://example.org/')[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bbd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_link(url: str,   # URL to read\n",
    "             heavy: bool = False,   # Use headless browser (requires extra setup steps before use)\n",
    "             sel: Optional[str] = None,  # Css selector to pull content from\n",
    "             useJina: bool = False, # Use Jina for the markdown conversion\n",
    "             ignore_links: bool = False, # Whether to keep links or not\n",
    "             ): \n",
    "    \"Reads a url and converts to markdown\"\n",
    "    if not heavy and not useJina: return read_html(url,sel=sel, ignore_links=ignore_links)\n",
    "    elif not heavy and useJina:   return httpx.get(f\"https://r.jina.ai/{url}\").text\n",
    "    elif heavy and not useJina: \n",
    "        import playwrightnb\n",
    "        return playwrightnb.url2md(url,sel=ifnone(sel,'body'))\n",
    "    elif heavy and useJina: raise NotImplementedError(\"Unsupported. No benefit to using Jina with playwrightnb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c7603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  * [ Get Started](./index.html)\\n\\n  * [ Tutorials](./tutorials/index.html) __\\n\\n    * [ FastHTML By Example](./tutorials/by_example.html)\\n\\n    * [ Web Devs Quickstart](./tutorials/quickstart_for_web_de'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_link('https://fastht.ml/docs/', sel='#quarto-content')[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061fa407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: FastHTML â€“ fasthtml\\n\\nURL Source: https://fastht.ml/docs/\\n\\nPublished Time: Sun, 06 Jul 2025 21:56:52 GMT\\n\\nMarkdown Content:\\nWelcome to the official FastHTML documentation.\\n\\nFastHTML is a new nex'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "read_link('https://fastht.ml/docs/',useJina=True)[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac33e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## On this page\\n\\n  * Installation\\n  * Usage\\n    * Getting help from AI\\n  * Next Steps\\n  * Other languages and related projects\\n\\n  * [__Report an issue](https://github.com/AnswerDotAI/fasthtml/issues/new)\\n\\n## Other Formats\\n\\n  * [ __CommonMark](index.html.md)\\n\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_link('https://fastht.ml/docs/',sel='#quarto-margin-sidebar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_url(*args,**kwargs):\n",
    "    warnings.warn(\"read_url() is deprecated, use read_link() instead\", \n",
    "                  DeprecationWarning, stacklevel=2)\n",
    "    return read_link(*args,**kwargs)\n",
    "\n",
    "read_url = functools.wraps(read_link)(read_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922abf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_275424/3158535638.py:1: DeprecationWarning: read_url() is deprecated, use read_link() instead\n",
      "  read_url('https://fastht.ml/docs/',sel='#quarto-margin-sidebar')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'## On this page\\n\\n  * Installation\\n  * Usage\\n    * Getting help from AI\\n  * Next Steps\\n  * Other languages and related projects\\n\\n  * [__Report an issue](https://github.com/AnswerDotAI/fasthtml/issues/new)\\n\\n## Other Formats\\n\\n  * [ __CommonMark](index.html.md)\\n\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_url('https://fastht.ml/docs/',sel='#quarto-margin-sidebar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41a6a8",
   "metadata": {},
   "source": [
    "### Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208dad18",
   "metadata": {},
   "source": [
    "#### Gist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_gist(url:str  # gist URL, of gist to read\n",
    "             ):\n",
    "    \"Returns raw gist content, or None\"\n",
    "    pattern = r'https://gist\\.github\\.com/([^/]+)/([^/]+)'\n",
    "    match = re.match(pattern, url)\n",
    "    if match:\n",
    "        user, gist_id = match.groups()\n",
    "        raw_url = f'https://gist.githubusercontent.com/{user}/{gist_id}/raw'\n",
    "        return httpx.get(raw_url).text\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8faab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#!/usr/bin/env python3\\nimport os, os.path, sys, urllib.parse, base64, subprocess\\n\\ndef on_iterm2(): return 'ITERM_SESSION_ID' in os.environ or os.environ.get('LC_TERMINAL','') == 'iTerm2'\\n\\ndef on_macOS\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_gist_url = \"https://gist.github.com/algal/a490024ad088de1b857531c83abef0a0\"\n",
    "read_gist(\"https://gist.github.com/algal/a490024ad088de1b857531c83abef0a0\")[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a81cd",
   "metadata": {},
   "source": [
    "#### URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ffa92",
   "metadata": {},
   "source": [
    "#### File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746101ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_gh_file(url:str # GitHub URL of the file to read\n",
    "                ):\n",
    "    \"Reads the contents of a file from its GitHub URL\"\n",
    "    pattern = r'https://github\\.com/([^/]+)/([^/]+)/blob/([^/]+)/(.+)'\n",
    "    replacement = r'https://raw.githubusercontent.com/\\1/\\2/refs/heads/\\3/\\4'\n",
    "    raw_url = re.sub(pattern, replacement, url)\n",
    "    return httpx.get(raw_url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7cb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# FastHTML\\n\\n\\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\\n\\nWelcome to the official FastHTML documentation.\\n\\nFastHTML is a new next-generation web framework for fast, scalable web\\napplic'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_gh_file(\"https://github.com/AnswerDotAI/fasthtml/blob/main/README.md\")[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc1f54",
   "metadata": {},
   "source": [
    "### Local Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3b8f9",
   "metadata": {},
   "source": [
    "####  Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db142751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_file(path:str):\n",
    "    \"returns file contents\"\n",
    "    with open(path,'r') as f: return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _is_unicode(filepath:str, sample_size:int=1024):\n",
    "    try:\n",
    "        with open(filepath, 'r') as file: sample = file.read(sample_size)\n",
    "        return True\n",
    "    except UnicodeDecodeError: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _is_unicode('_quarto.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4d45a2",
   "metadata": {},
   "source": [
    "#### Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f30d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_dir(path: str,                          # path to read\n",
    "             unicode_only: bool = True,             # ignore non-unicode files\n",
    "             included_patterns: List[str] = [\"*\"],       # glob pattern of files to include\n",
    "             excluded_patterns: List[str] = [\".git/**\"], # glob pattern of files to exclude\n",
    "             verbose: bool = False,                # log paths of files being read\n",
    "             as_dict: bool = False                  # returns dict of {path,content}\n",
    "            ) -> Union[str, Dict[str, str]]:            # returns string with contents of files read\n",
    "    \"\"\"Reads files in path, returning a dict with the filenames and contents if as_dict=True, otherwise concatenating file contents into a single string. Takes optional glob patterns for files to include or exclude.\"\"\"\n",
    "    pattern = '**/*'\n",
    "    result = {}\n",
    "    for file_path in glob.glob(os.path.join(path, pattern), recursive=True):\n",
    "        if any(fnmatch.fnmatch(file_path, pat) for pat in excluded_patterns):\n",
    "            continue\n",
    "        if not any(fnmatch.fnmatch(file_path, pat) for pat in included_patterns):\n",
    "            continue\n",
    "        if os.path.isfile(file_path):\n",
    "            if unicode_only and not _is_unicode(file_path):\n",
    "                continue\n",
    "            if verbose:\n",
    "                print(f\"Including {file_path}\")\n",
    "            with open(file_path, 'r', errors='ignore') as f:\n",
    "                result[file_path] = f.read()\n",
    "    if not as_dict:\n",
    "        return '\\n'.join([f\"--- File: {file_path} ---\\n{v}\\n--- End of {file_path} ---\" for file_path,v in result.items()])\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498ea9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--- File: ./_quarto.yml ---\\nproject:\\n  type: website\\n\\nformat:\\n  html:\\n    theme: cosmo\\n    css: styles.css\\n    toc: true\\n    keep-md: true\\n  commonmark: default\\n\\nwebsite:\\n  twitter-card: true\\n  open-g'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dir('.',verbose=False)[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1b4aa",
   "metadata": {},
   "source": [
    "### PDF reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_pdf(file_path: str # path of PDF file to read\n",
    "            ) -> str:\n",
    "    \"Reads the text of a PDF with PdfReader\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PdfReader(file)\n",
    "        return ' '.join(page.extract_text() for page in reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db8ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n \\n \\n \\n \\n \\nThis is a test PDF document. \\nIf you can read this, you have Adobe Acrobat Reader installed on your computer. '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_pdf('./test_dir/test.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76babf",
   "metadata": {},
   "source": [
    "### YT Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# def read_yt_transcript(yt_url: str):\n",
    "#     \"Gets the text of a YouTube transcript\"\n",
    "#     from pytube import YouTube\n",
    "#     from youtube_transcript_api import YouTubeTranscriptApi\n",
    "#     try:\n",
    "#         yt = YouTube(yt_url)\n",
    "#         video_id = yt.video_id\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred parsing yt urul: {e}\")\n",
    "#         return None\n",
    "#     transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "#     return ' '.join(entry['text'] for entry in transcript) \n",
    "\n",
    "# yt_url = \"https://www.youtube.com/watch?v=BGgsoIgbT_Y\"\n",
    "# s = read_yt_transcript(yt_url)\n",
    "# s[:200]\n",
    "# Currently seems broken, removing #| export "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe765cb",
   "metadata": {},
   "source": [
    "### Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da885dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_google_sheet(url: str # URL of a Google Sheet to read\n",
    "                     ):\n",
    "    \"Reads the contents of a Google Sheet into text\"\n",
    "    sheet_id = url.split('/d/')[1].split('/')[0]\n",
    "    csv_url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&id={sheet_id}&gid=0'\n",
    "    res = requests.get(url=csv_url)\n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c10b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Band Pull Around/Aparts\\r\\nShoulder Dislocations Straight\\r\\nShoulder Dislocations Side\\r\\nSuperman Dislocation\\r\\nScorpion Chest Stretch\\r\\nLatt Pulldown\\r\\nTwisty Shoulders\\r\\nRotator Cuff Pull\\r\\nWide bent over row'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_google_sheet('https://docs.google.com/spreadsheets/d/17Q3LzRCyM4md28IBxzSSERpaafLgOH8MjH5r6UkyVz8/edit?gid=0#gid=0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bac4f4",
   "metadata": {},
   "source": [
    "### Google Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gdoc_url_to_parseable(url: str):\n",
    "    pattern = r'(https://docs\\.google\\.com/document/d/[^/]+)/edit'\n",
    "    replacement = r'\\1/export?format=html'\n",
    "    return re.sub(pattern, replacement, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.google.com/document/d/13g-IDyuJyk5wE60bOH1YhhFgW8rlh2LnSXccBS0CQd0/export?format=html\n"
     ]
    }
   ],
   "source": [
    "result = _gdoc_url_to_parseable(\"https://docs.google.com/document/d/13g-IDyuJyk5wE60bOH1YhhFgW8rlh2LnSXccBS0CQd0/edit\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4585ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_gdoc(url: str  # URL of Google Doc to read\n",
    "             ):\n",
    "    \"Gets the text content of a Google Doc using html2text\"\n",
    "    import html2text\n",
    "    doc_url = url\n",
    "    doc_id = doc_url.split('/d/')[1].split('/')[0]\n",
    "    export_url = f'https://docs.google.com/document/d/{doc_id}/export?format=html'\n",
    "    html_doc_content = requests.get(export_url).text\n",
    "    doc_content = html2text.html2text(html_doc_content)\n",
    "    return doc_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e6e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Top heading\\n\\nHello this is a context reading test\\n\\n## Heading 2\\n\\nBolded text is here as well as italisized\\n\\n  * I have bullets\\n  * Of things\\n\\n## Heading 3\\n\\nAnd ordered\\n\\n  1. Lists\\n  2. Of\\n  3. Thing'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_gdoc(\"https://docs.google.com/document/d/13g-IDyuJyk5wE60bOH1YhhFgW8rlh2LnSXccBS0CQd0/edit\")[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093cb6ad",
   "metadata": {},
   "source": [
    "### Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_arxiv(url:str, # arxiv PDF URL, or arxiv abstract URL, or arxiv ID\n",
    "               save_pdf:bool=False, # True, will save the downloaded PDF\n",
    "               save_dir:str='.' # directory in which to save the PDF\n",
    "              ):\n",
    "    \"Get paper information from arxiv URL or ID, optionally saving PDF to disk\"\n",
    "    import re, httpx, tarfile, io, os\n",
    "    import xml.etree.ElementTree as ET\n",
    "    \n",
    "    if save_pdf: os.makedirs(save_dir, exist_ok=True)\n",
    "    arxiv_id = url.split('/')[-1] if '/' in url else url\n",
    "    \n",
    "    # Remove version number if present but save it for downloads\n",
    "    version = re.search(r'v(\\d+)$', arxiv_id)\n",
    "    version_num = version.group(1) if version else None\n",
    "    arxiv_id = re.sub(r'v\\d+$', '', arxiv_id)\n",
    "    \n",
    "    api_url = f'https://export.arxiv.org/api/query?id_list={arxiv_id}'\n",
    "    \n",
    "    response = httpx.get(api_url)\n",
    "    \n",
    "    if response.status_code != 200: raise Exception(f\"Failed to fetch arxiv data: {response.status_code}\")\n",
    "    \n",
    "    root = ET.fromstring(response.text)\n",
    "    ns = {'arxiv': 'http://www.w3.org/2005/Atom'}\n",
    "    entry = root.find('arxiv:entry', ns)\n",
    "    if entry is None: raise Exception(\"No paper found\")\n",
    "    \n",
    "    links = entry.findall('arxiv:link', ns)\n",
    "    pdf_url = next((l.get('href') for l in links if l.get('title') == 'pdf'), None)\n",
    "    \n",
    "    result = {\n",
    "        'title': entry.find('arxiv:title', ns).text.strip(),\n",
    "        'authors': [author.find('arxiv:name', ns).text for author in entry.findall('arxiv:author', ns)],\n",
    "        'summary': entry.find('arxiv:summary', ns).text.strip(),\n",
    "        'published': entry.find('arxiv:published', ns).text,\n",
    "        'link': entry.find('arxiv:id', ns).text,\n",
    "        'pdf_url': pdf_url\n",
    "    }\n",
    "    \n",
    "    if save_pdf and pdf_url:\n",
    "        pdf_response = httpx.get(pdf_url)\n",
    "        if pdf_response.status_code == 200:\n",
    "            pdf_filename = f\"{arxiv_id}{'v'+version_num if version_num else ''}.pdf\"\n",
    "            pdf_path = os.path.join(save_dir, pdf_filename)\n",
    "            with open(pdf_path, 'wb') as f:\n",
    "                f.write(pdf_response.content)\n",
    "            result['pdf_path'] = pdf_path\n",
    "    \n",
    "    source_url = f'https://arxiv.org/e-print/{arxiv_id}{\"v\"+version_num if version_num else \"\"}'\n",
    "    try:\n",
    "        source_response = httpx.get(source_url)\n",
    "        if source_response.status_code == 200:\n",
    "            # Try to extract main tex file from tar archive\n",
    "            tar_content = io.BytesIO(source_response.content)\n",
    "            with tarfile.open(fileobj=tar_content, mode='r:*') as tar:\n",
    "                # Look for main tex file\n",
    "                tex_files = [f for f in tar.getnames() if f.endswith('.tex')]\n",
    "                if tex_files:\n",
    "                    main_tex = tar.extractfile(tex_files[0])\n",
    "                    result['source'] = main_tex.read().decode('utf-8', errors='ignore')\n",
    "    except Exception as e:\n",
    "        result['source_error'] = str(e)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d190780",
   "metadata": {},
   "source": [
    "### GitHub Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec940333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _gh_ssh_from_gh_url(gh_repo_address:str):\n",
    "    \"Given a GH URL or SSH remote address, returns a GH URL or None\"\n",
    "    pattern = r'https://github\\.com/([^/]+)/([^/]+)(?:/.*)?'\n",
    "    if gh_repo_address.startswith(\"git@github.com:\"): return gh_repo_address\n",
    "    elif match := re.match(pattern, gh_repo_address):\n",
    "        user, repo = match.groups()\n",
    "        return f'git@github.com:{user}/{repo}.git'\n",
    "    # Not a GitHub URL or a GitHub SSH remote address\n",
    "    else: return None\n",
    "\n",
    "def _get_default_branch(repo_path:str):\n",
    "    \"master or main\"\n",
    "    try:\n",
    "        result = subprocess.run(['git', 'symbolic-ref', 'refs/remotes/origin/HEAD'], \n",
    "                                cwd=repo_path, capture_output=True, text=True, check=True)\n",
    "        return result.stdout.strip().split('/')[-1]\n",
    "    except subprocess.CalledProcessError:\n",
    "        return 'main'  # Default to 'main' if we can't determine the branch\n",
    "\n",
    "def _get_git_repo(gh_ssh:str):\n",
    "    \"Fetchs from a GH SSH address, returns a path\"\n",
    "    repo_name = gh_ssh.split('/')[-1].replace('.git', '')\n",
    "    cache_dir = Path(os.environ.get('XDG_CACHE_HOME', Path.home() / '.cache')) / 'contextkit_git_clones'\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    repo_dir = cache_dir / repo_name\n",
    "\n",
    "    if repo_dir.exists():\n",
    "        try:\n",
    "            subprocess.run(['git', 'fetch'], cwd=repo_dir, check=True, capture_output=True)\n",
    "            default_branch = _get_default_branch(repo_dir)\n",
    "            subprocess.run(['git', 'reset', '--hard', f'origin/{default_branch}'], \n",
    "                           cwd=repo_dir, check=True, capture_output=True)\n",
    "            return str(repo_dir)\n",
    "        except subprocess.CalledProcessError:\n",
    "            shutil.rmtree(repo_dir)  # Remove the cached directory if update fails\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        try:\n",
    "            print(\"Cloning repo.\")\n",
    "            subprocess.run(['git', 'clone', gh_ssh], cwd=temp_dir, check=True, capture_output=False)\n",
    "            cloned_dir = Path(temp_dir) / repo_name\n",
    "            shutil.move(str(cloned_dir), str(repo_dir))\n",
    "            return str(repo_dir)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error cloning repo from cwd {temp_dir} with error {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_gh_repo(path_or_url:str,    # Repo's GitHub URL, or GH SSH address, or file path\n",
    "                 as_dict:bool=True,  # if True, will return repo contents {path,content} dict\n",
    "                 verbose:bool=False  # if True, will log paths of files being read\n",
    "                ):\n",
    "    \"Repo contents from path, GH URL, or GH SSH address\"\n",
    "    gh_ssh = _gh_ssh_from_gh_url(path_or_url)\n",
    "    path = path_or_url if not gh_ssh else _get_git_repo(gh_ssh)\n",
    "    return read_dir(path,verbose=verbose,as_dict=as_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debcf17a",
   "metadata": {},
   "source": [
    "How to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jhoward/.cache/contextkit_git_clones/claudette/llms.txt',\n",
       " '/Users/jhoward/.cache/contextkit_git_clones/claudette/00_core.ipynb',\n",
       " '/Users/jhoward/.cache/contextkit_git_clones/claudette/_quarto.yml',\n",
       " '/Users/jhoward/.cache/contextkit_git_clones/claudette/LICENSE',\n",
       " '/Users/jhoward/.cache/contextkit_git_clones/claudette/styles.css']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghurl=\"https://github.com/AnswerDotAI/claudette\"\n",
    "d = read_gh_repo(ghurl,as_dict=True)\n",
    "list(d.keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefe903",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e85fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
